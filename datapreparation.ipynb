{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment below to install animaloc\n",
    "#!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import PIL\n",
    "import torchvision\n",
    "import numpy\n",
    "import cv2\n",
    "import skimage\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from albumentations import PadIfNeeded\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from animaloc.data import ImageToPatches, PatchesBuffer, save_batch_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiling data for annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For GeoTiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patches(img_path:Path,dest_dir:Path,tilesize=512):\n",
    "\n",
    "    # create directory\n",
    "    if os.path.exists(dest_dir):\n",
    "        shutil.rmtree(dest_dir)\n",
    "        os.mkdir(dest_dir)\n",
    "        print(\"emptying directory:\", dest_dir)\n",
    "    else:\n",
    "        os.mkdir(dest_dir)\n",
    "        print(\"creating directory:\", dest_dir)\n",
    "    \n",
    "    # window reading with rasterio\n",
    "    handler = rasterio.open(img_path)\n",
    "    height, width = handler.meta['height'], handler.meta['width']\n",
    "    coordinates = dict()\n",
    "    count = 0\n",
    "    for i,j in tqdm(product(list(range(0,height,tilesize)),list(range(0,width,tilesize)))):\n",
    "        window = Window(j, i, tilesize, tilesize)\n",
    "        \n",
    "        try:\n",
    "            chunk = handler.read(window=window)\n",
    "            c,h,w = chunk.shape\n",
    "            xmin, xmax = j, j+w\n",
    "            ymin, ymax = i, i+h\n",
    "            x_center = 0.5*(xmin+xmax)\n",
    "            y_center = 0.5*(ymin+ymax)\n",
    "            n_unique = np.unique(chunk).size\n",
    "            if n_unique == 1:\n",
    "                continue\n",
    "            count += 1\n",
    "            filename = img_path.name.split('.')[0] + f\"-{j}-{i}.png\"\n",
    "            coordinates[count] = [xmin,xmax,ymin,ymax,x_center,y_center,filename]\n",
    "\n",
    "            # save to disk\n",
    "            chunk = np.transpose(chunk,(1,2,0))\n",
    "            skimage.io.imsave(dest_dir/filename,chunk)          \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Failed for\",(i,j),e)\n",
    "            pass\n",
    "\n",
    "    cols = ['xmin','xmax','ymin','ymax','x_center','y_center','filename']\n",
    "    coordinates = pd.DataFrame.from_dict(coordinates,\n",
    "                                        orient='index',\n",
    "                                        columns=cols)\n",
    "    coordinates.to_csv(dest_dir/f\"coordinates{img_path.name.split('.')[0]}.csv\",index=False)\n",
    "    handler.close()\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datapath in Path(\"../annotation_data/camp6/\").iterdir():\n",
    "datapath = Path(\"../annotation_data/camp6/150m_RGB.tif\")\n",
    "dest_dir = datapath.parent/(datapath.name.split('.')[0])\n",
    "# coordinates =  save_patches(datapath,dest_dir,tilesize=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Images (jpg, rgb etc.)\n",
    "Using Herdnet code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/workspace/HerdNet\n"
     ]
    }
   ],
   "source": [
    "!pwd # current working dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiling validation data\n",
    "Path(\"../general_dataset/val_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../general_dataset/val 640 640 100 \\\n",
    "    ../general_dataset/val_splits \\\n",
    "    -csv ../general_dataset/groundtruth/csv/val_big_size_A_B_E_K_WH_WB.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiling training data\n",
    "Path(\"../general_dataset/train_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../general_dataset/train 640 640 100 \\\n",
    "    ../general_dataset/train_splits \\\n",
    "    -csv ../general_dataset/groundtruth/csv/train_big_size_A_B_E_K_WH_WB.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiling test data\n",
    "Path(\"../general_dataset/test_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../general_dataset/test 640 640 100 \\\n",
    "    ../general_dataset/test_splits \\\n",
    "    -csv ../general_dataset/groundtruth/csv/test_big_size_A_B_E_K_WH_WB.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting patches: 100%|██████████████████| 1226/1226 [1:02:52<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# tiling Annotation data\n",
    "\n",
    "# Destination of splits\n",
    "Path(\"../EBP-Lindanda-cam0-splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../EBP-Lindanda-cam0 512 512 64 \\\n",
    "    ../EBP-Lindanda-cam0-splits \\\n",
    "    -min 0.0 -all True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiling data from Savmap dataset\n",
    "# path_gt = '../savmap_dataset_v2/gt.csv'\n",
    "# df_gt = pd.read_csv(path_gt)\n",
    "# df_gt['labels'] = 0\n",
    "# df_gt.rename(columns={'filename':'images',\n",
    "#                       'xmin':'x_min',\n",
    "#                       'xmax':'x_max',\n",
    "#                       'ymin':'y_min',\n",
    "#                       'ymax':'y_max'\n",
    "#                       },inplace=True)\n",
    "\n",
    "# df_gt.to_csv(path_gt,index=False,sep=',')\n",
    "\n",
    "Path(\"../savmap_dataset_v2/train_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../savmap_dataset_v2/images 640 640 100 \\\n",
    "    ../savmap_dataset_v2/train_splits \\\n",
    "    -csv ../savmap_dataset_v2/gt.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling emtpy and non empty images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample training data\n",
    "\n",
    "directory = Path(r\"../savmap_dataset_v2/train/\")\n",
    "labels = directory/'labels'\n",
    "dest_images = directory/'images_nonempty'\n",
    "source_images = directory/'images'\n",
    "\n",
    "# create destination images\n",
    "dest_images.mkdir(exist_ok=True)\n",
    "\n",
    "# move non empty images\n",
    "# -- Uncomment to run > Be careful\n",
    "# for file in labels.iterdir():\n",
    "#     img_name = file.name.split('.')[0]+'.JPG'\n",
    "#     if (source_images/img_name).exists():\n",
    "#         os.rename(src=source_images/img_name,\n",
    "#                 dst=dest_images/img_name)\n",
    "\n",
    "# # and empty \n",
    "# -- Uncomment to run > Be careful!!\n",
    "# num_non_empty = len(list(labels.iterdir()))\n",
    "# num_empty_target = num_non_empty\n",
    "# empty_images = list(source_images.iterdir())\n",
    "# random.seed(41) # seeding for reproducibility\n",
    "# random.shuffle(empty_images) # shuffle\n",
    "# for file in empty_images[:num_empty_target]:\n",
    "#     img_name = file.name\n",
    "#     os.rename(src=file,\n",
    "#                 dst=dest_images/img_name)\n",
    "\n",
    "# rename folders\n",
    "# os.rename(src=source_images,dst=directory/'images_empty')\n",
    "# os.rename(src=dest_images,dst=directory/'images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list((directory/'images_empty').iterdir())),\\\n",
    "    len(list((directory/\"images\").iterdir())),\\\n",
    "        len(list((directory/\"labels\").iterdir()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from animaloc.datasets import CSVDataset\n",
    "from animaloc.data.transforms import MultiTransformsWrapper, DownSample, PointsToMask, FIDT\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_size = 640\n",
    "# num_classes = 7\n",
    "down_ratio = 1\n",
    "\n",
    "val_dataset = CSVDataset(\n",
    "    csv_file = '../wildlife_localizer_data/val/gt.csv',\n",
    "    root_dir = '../wildlife_localizer_data/val',\n",
    "    albu_transforms = [A.Normalize(p=1.0)],\n",
    "    end_transforms = [DownSample(down_ratio=down_ratio, anno_type='bbox')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.anno_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../wildlife_localizer_data/val/gt.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(labels['labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = DataLoader(dataset = val_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.transpose(images.numpy(),(1,2,0))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating YOLO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images dimensions\n",
    "height,width = 640, 640\n",
    "\n",
    "# Create label directory\n",
    "for directory in Path(\"../wildlife_localizer_data/\").iterdir():\n",
    "    if not directory.is_dir():\n",
    "        continue \n",
    "    labels_dir = Path(os.path.join(directory,'labels'))\n",
    "    labels_dir.mkdir(exist_ok=True,parents=False) # create directory if it does not exist\n",
    "    labels = pd.read_csv(os.path.join(directory,'gt.csv'))\n",
    "    #-- Saving labels in YOLO format\n",
    "    for img_filename,df_group in tqdm(labels.groupby(by='images'),desc=directory.name):\n",
    "        df_group['width'] = (df_group['x_max'] - df_group['x_min'])/width \n",
    "        df_group['height'] = (df_group['y_max'] - df_group['y_min'])/height\n",
    "        df_group['x'] = (0.5*(df_group['x_min'] + df_group['x_max']))/width # x center\n",
    "        df_group['y'] = (0.5*(df_group['y_min'] + df_group['y_max']))/height # y center\n",
    "        df_group['labels'] = 0 \n",
    "\n",
    "        # print('\\n\\n',directory.name,'\\n',df_group[['labels','x','y','width','height']])\n",
    "        # break\n",
    "\n",
    "        # uncomment to save labels files\n",
    "        labels_filename     = img_filename.split('.')[0] + '.txt'\n",
    "        if len(df_group)>0:\n",
    "            cols = ['labels','x','y','width','height']\n",
    "            df_group[cols].to_csv(os.path.join(labels_dir,labels_filename),\n",
    "                                    sep=\" \",\n",
    "                                    header=False,\n",
    "                                    index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2750/2750 [00:09<00:00, 303.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# for savmap data\n",
    "directory = Path(\"../savmap_dataset_v2/train/\")\n",
    "labels_dir = Path(os.path.join(directory,'labels'))\n",
    "labels_dir.mkdir(exist_ok=True,parents=False) # create directory if it does not exist\n",
    "labels = pd.read_csv(os.path.join(directory,'gt.csv'))\n",
    "#-- Saving labels in YOLO format\n",
    "for img_filename,df_group in tqdm(labels.groupby(by='images'),desc=directory.name):\n",
    "    df_group['width'] = (df_group['x_max'] - df_group['x_min'])/width \n",
    "    df_group['height'] = (df_group['y_max'] - df_group['y_min'])/height\n",
    "    df_group['x'] = (0.5*(df_group['x_min'] + df_group['x_max']))/width # x center\n",
    "    df_group['y'] = (0.5*(df_group['y_min'] + df_group['y_max']))/height # y center\n",
    "    df_group['labels'] = 0 \n",
    "\n",
    "    # print('\\n\\n',directory.name,'\\n',df_group[['labels','x','y','width','height']])\n",
    "    # break\n",
    "\n",
    "    # uncomment to save labels files\n",
    "    labels_filename = img_filename.split('.')[0] + '.txt'\n",
    "    if len(df_group)>0:\n",
    "        cols = ['labels','x','y','width','height']\n",
    "        df_group[cols].to_csv(os.path.join(labels_dir,labels_filename),\n",
    "                                    sep=\" \",\n",
    "                                    header=False,\n",
    "                                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30607, 2750, 33357)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control splitting\n",
    "num_missing = 0\n",
    "num_found = 0\n",
    "num_total = 0\n",
    "for path in Path(\"../savmap_dataset_v2/train/images\").iterdir():\n",
    "    filename = path.name.split('.')[0]\n",
    "    labelpath = Path(\"../savmap_dataset_v2/train/labels\")/(filename + '.txt')\n",
    "    num_total += 1\n",
    "    if not labelpath.exists():\n",
    "        num_missing += 1\n",
    "    else:\n",
    "        num_found += 1\n",
    "\n",
    "num_missing,num_found,num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(os.path.join(directory,'gt.csv'))\n",
    "labels['labels'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Savmap data\n",
    "Saving bounding boxes in VOC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import torch \n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.ops import nms\n",
    "from torchvision.transforms import PILToTensor\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = Path(\"../savmap_dataset_v2/savmap_annotations_2014.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpd.read_file(annotations_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[data['IMAGEUUID']=='0a3ed15cfab4453795564140e8fde8ba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uuid = '0a3ed15cfab4453795564140e8fde8ba'\n",
    "# polygons = data.loc[data['IMAGEUUID']==uuid,'geometry']\n",
    "# polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = dict()\n",
    "count = 0\n",
    "pil_to_tensor = PILToTensor()\n",
    "for uuid in tqdm(np.unique(data.IMAGEUUID),desc='Getting bbox'):\n",
    "\n",
    "    # identifier, filenmae w/o suffix\n",
    "    uuid = str(uuid)\n",
    "\n",
    "    # load img as tensor\n",
    "    path_to_img = f\"../savmap_dataset_v2/images/{uuid}.JPG\"\n",
    "    img_pil = Image.open(path_to_img)\n",
    "    img_tensor = pil_to_tensor(img_pil)\n",
    "\n",
    "    # get boxes\n",
    "    polygons = data.loc[data['IMAGEUUID']==uuid,'geometry']\n",
    "    boxes = np.array([list(polygon.bounds) for polygon in polygons])\n",
    "    boxes = torch.from_numpy(boxes).float()\n",
    "\n",
    "    # apply non max suppression o discard overlaping polygons\n",
    "    areas = abs((boxes[:,2] - boxes[:,0])*(boxes[:,3] - boxes[:,1]))\n",
    "    indices = nms(boxes=boxes,\n",
    "                  scores= 1/areas, # discarding larger bbox when they overlap\n",
    "                  iou_threshold=0.1)\n",
    "    bbox = boxes[indices].numpy()\n",
    "\n",
    "    # save bbox\n",
    "    start, end = count, count+bbox.shape[0]\n",
    "    for idx,i in enumerate(range(start, end)):\n",
    "        bboxes[i] = [uuid,] + bbox[idx].tolist()\n",
    "    count = end\n",
    "# print('retained bbox indes:',indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['filename','x_min','y_min','x_max','y_max']\n",
    "gt_bboxes = pd.DataFrame.from_dict(data=bboxes,\n",
    "                       orient='index',\n",
    "                       columns=columns)\n",
    "\n",
    "for col in columns:\n",
    "    if col != 'images':\n",
    "        gt_bboxes[col] = gt_bboxes[col].apply(int)\n",
    "    else:\n",
    "        gt_bboxes[col] = gt_bboxes[col].apply(lambda x: f\"{x}.JPG\")\n",
    "\n",
    "gt_bboxes['labels'] = 0 # class\n",
    "gt_bboxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discarding invalid coordinates\n",
    "# gt_bboxes.loc[gt_bboxes.min(axis=1,numeric_only=True)>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: drawing bounding boxes\n",
    "\n",
    "# load img as tensor\n",
    "filename = gt_bboxes['filename'].sample(1).iloc[0]\n",
    "path_to_img = f\"../savmap_dataset/{filename}\"\n",
    "img_pil = Image.open(path_to_img)\n",
    "img_tensor = PILToTensor()(img_pil)\n",
    "\n",
    "boxes = gt_bboxes.loc[gt_bboxes['filename'] == filename, ['x_min','y_min','x_max','y_max']].to_numpy()\n",
    "boxes = torch.from_numpy(boxes)\n",
    "\n",
    "img_with_box = draw_bounding_boxes(img_tensor,\n",
    "                                   boxes=boxes,\n",
    "                                   colors=\"red\",\n",
    "                                   width=5).numpy().transpose((1,2,0))\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.imshow(img_with_box)\n",
    "plt.title(filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from animaloc.data import ImageToPatches\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.models.yolov8 import Yolov8DetectionModel\n",
    "from sahi.utils.cv import read_image\n",
    "from sahi.predict import get_sliced_prediction, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "path_to_weights = Path('../yolo-runs/exp4/weights/best.pt')\n",
    "# model = YOLO('yolov8s.pt',task='detect').load(path_to_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load image\n",
    "# dir_images = Path(\"../savmap_dataset_v2/train/images\").iterdir()\n",
    "# img = Image.open(next(dir_images))\n",
    "\n",
    "# patcher = ImageToPatches(img,size=(640,640),overlap=0)\n",
    "# patches = patcher.make_patches()\n",
    "\n",
    "# # model.predict()\n",
    "# print(len(patcher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = patcher.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(patches[9].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sahi\n",
    "# detection_model = AutoDetectionModel.from_pretrained(\n",
    "#     model_type='yolov8',\n",
    "#     model_path=path_to_weights,\n",
    "#     image_size=640,\n",
    "#     confidence_threshold=0.3,\n",
    "#     device=\"cpu\", # or 'cuda:0'\n",
    "# )\n",
    "\n",
    "detection_model = Yolov8DetectionModel(model_path=path_to_weights,\n",
    "                                      confidence_threshold=0.3,\n",
    "                                      device=\"cpu\" # or 'cuda:0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 16 number of slices.\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"../dummy_image.jpg\")\n",
    "result = get_sliced_prediction(img, \n",
    "                               detection_model,\n",
    "                               slice_height=640,\n",
    "                               slice_width=640,\n",
    "                               overlap_height_ratio=0.2,\n",
    "                               overlap_width_ratio=0.2,\n",
    "                               postprocess_type='NMS',\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.export_visuals(export_dir=\"./tmp/\",hide_labels=True,hide_conf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': None,\n",
       "  'bbox': [383.18536376953125, 422.7789306640625, 92.33203125, 76.5166015625],\n",
       "  'score': 0.7291696071624756,\n",
       "  'category_id': 0,\n",
       "  'category_name': 'wildlife',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 7064},\n",
       " {'image_id': None,\n",
       "  'bbox': [555.7026977539062,\n",
       "   273.54473876953125,\n",
       "   53.543212890625,\n",
       "   40.183349609375],\n",
       "  'score': 0.7242732644081116,\n",
       "  'category_id': 0,\n",
       "  'category_name': 'wildlife',\n",
       "  'segmentation': [],\n",
       "  'iscrowd': 0,\n",
       "  'area': 2151}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_coco_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wildaidata-test', 'p1/p2/000113a692ba61cd55ea3acb9c2f9c41709710a1_S2.JPG')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parsing s3 url\n",
    "url = 's3://wildaidata-test/p1/p2/000113a692ba61cd55ea3acb9c2f9c41709710a1_S2.JPG'\n",
    "s3_img = Path(url)\n",
    "\n",
    "img_path = s3_img\n",
    "bucket = list(img_path.parents)[-3]\n",
    "bucket_name = str(bucket).split('/')[-1]\n",
    "filename = str(img_path).replace(f\"{str(bucket)}/\",'')\n",
    "\n",
    "bucket_name, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wildaidata-test', 'p1/p2/000113a692ba61cd55ea3acb9c2f9c41709710a1_S2.JPG')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = urlparse(url, allow_fragments=False)\n",
    "bucket_name = r.netloc\n",
    "key = r.path.lstrip('/')\n",
    "bucket_name,key"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "herdnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
