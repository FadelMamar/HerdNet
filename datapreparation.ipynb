{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import PIL\n",
    "import torchvision\n",
    "import numpy\n",
    "import cv2\n",
    "import skimage\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from albumentations import PadIfNeeded\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from animaloc.data import ImageToPatches, PatchesBuffer, save_batch_images\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data for annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For GeoTiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patches(img_path:Path,dest_dir:Path,tilesize=512):\n",
    "\n",
    "    # create directory\n",
    "    if os.path.exists(dest_dir):\n",
    "        shutil.rmtree(dest_dir)\n",
    "        os.mkdir(dest_dir)\n",
    "        print(\"emptying directory:\", dest_dir)\n",
    "    else:\n",
    "        os.mkdir(dest_dir)\n",
    "        print(\"creating directory:\", dest_dir)\n",
    "    \n",
    "    # window reading with rasterio\n",
    "    handler = rasterio.open(img_path)\n",
    "    height, width = handler.meta['height'], handler.meta['width']\n",
    "    coordinates = dict()\n",
    "    count = 0\n",
    "    for i,j in tqdm(product(list(range(0,height,tilesize)),list(range(0,width,tilesize)))):\n",
    "        window = Window(j, i, tilesize, tilesize)\n",
    "        \n",
    "        try:\n",
    "            chunk = handler.read(window=window)\n",
    "            c,h,w = chunk.shape\n",
    "            xmin, xmax = j, j+w\n",
    "            ymin, ymax = i, i+h\n",
    "            x_center = 0.5*(xmin+xmax)\n",
    "            y_center = 0.5*(ymin+ymax)\n",
    "            n_unique = np.unique(chunk).size\n",
    "            if n_unique == 1:\n",
    "                continue\n",
    "            count += 1\n",
    "            filename = img_path.name.split('.')[0] + f\"-{j}-{i}.png\"\n",
    "            coordinates[count] = [xmin,xmax,ymin,ymax,x_center,y_center,filename]\n",
    "\n",
    "            # save to disk\n",
    "            chunk = np.transpose(chunk,(1,2,0))\n",
    "            skimage.io.imsave(dest_dir/filename,chunk)          \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Failed for\",(i,j),e)\n",
    "            pass\n",
    "\n",
    "    cols = ['xmin','xmax','ymin','ymax','x_center','y_center','filename']\n",
    "    coordinates = pd.DataFrame.from_dict(coordinates,\n",
    "                                        orient='index',\n",
    "                                        columns=cols)\n",
    "    coordinates.to_csv(dest_dir/f\"coordinates{img_path.name.split('.')[0]}.csv\",index=False)\n",
    "    handler.close()\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datapath in Path(\"../annotation_data/camp6/\").iterdir():\n",
    "datapath = Path(\"../annotation_data/camp6/150m_RGB.tif\")\n",
    "dest_dir = datapath.parent/(datapath.name.split('.')[0])\n",
    "# coordinates =  save_patches(datapath,dest_dir,tilesize=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Images (jpg, rgb etc.)\n",
    "Using Herdnet code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd # current working dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting validation data\n",
    "Path(\"../general_dataset/val_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../general_dataset/val 640 640 100 \\\n",
    "    ../general_dataset/val_splits \\\n",
    "    -csv ../general_dataset/groundtruth/csv/val_big_size_A_B_E_K_WH_WB.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training data\n",
    "Path(\"../general_dataset/train_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../general_dataset/train 640 640 100 \\\n",
    "    ../general_dataset/train_splits \\\n",
    "    -csv ../general_dataset/groundtruth/csv/train_big_size_A_B_E_K_WH_WB.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting test data\n",
    "Path(\"../general_dataset/test_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../general_dataset/test 640 640 100 \\\n",
    "    ../general_dataset/test_splits \\\n",
    "    -csv ../general_dataset/groundtruth/csv/test_big_size_A_B_E_K_WH_WB.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the buffer: 100%|████████████████████| 654/654 [04:41<00:00,  2.32it/s]\n",
      "Exporting patches: 100%|██████████████████████| 654/654 [18:38<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "# splitting savmap data\n",
    "Path(\"../savmap_dataset_v2/images_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../savmap_dataset_v2/images 640 640 100 \\\n",
    "    ../savmap_dataset_v2/images_splits \\\n",
    "    -csv ../savmap_dataset_v2/gt.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling emtpy and non empty images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample training data\n",
    "\n",
    "directory = Path(r\"../savmap_dataset_v2/train/\")\n",
    "labels = directory/'labels'\n",
    "dest_images = directory/'images_nonempty'\n",
    "source_images = directory/'images'\n",
    "\n",
    "# create destination images\n",
    "dest_images.mkdir(exist_ok=True)\n",
    "\n",
    "# move non empty images\n",
    "# -- Uncomment to run > Be careful\n",
    "# for file in labels.iterdir():\n",
    "#     img_name = file.name.split('.')[0]+'.JPG'\n",
    "#     if (source_images/img_name).exists():\n",
    "#         os.rename(src=source_images/img_name,\n",
    "#                 dst=dest_images/img_name)\n",
    "\n",
    "# # and empty \n",
    "# -- Uncomment to run > Be careful!!\n",
    "# num_non_empty = len(list(labels.iterdir()))\n",
    "# num_empty_target = num_non_empty\n",
    "# empty_images = list(source_images.iterdir())\n",
    "# random.seed(41) # seeding for reproducibility\n",
    "# random.shuffle(empty_images) # shuffle\n",
    "# for file in empty_images[:num_empty_target]:\n",
    "#     img_name = file.name\n",
    "#     os.rename(src=file,\n",
    "#                 dst=dest_images/img_name)\n",
    "\n",
    "# rename folders\n",
    "# os.rename(src=source_images,dst=directory/'images_empty')\n",
    "# os.rename(src=dest_images,dst=directory/'images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27857, 5500, 2750)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list((directory/'images_empty').iterdir())),\\\n",
    "    len(list((directory/\"images\").iterdir())),\\\n",
    "        len(list((directory/\"labels\").iterdir()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from animaloc.datasets import CSVDataset\n",
    "from animaloc.data.transforms import MultiTransformsWrapper, DownSample, PointsToMask, FIDT\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_size = 640\n",
    "# num_classes = 7\n",
    "down_ratio = 1\n",
    "\n",
    "val_dataset = CSVDataset(\n",
    "    csv_file = '../wildlife_localizer_data/val/gt.csv',\n",
    "    root_dir = '../wildlife_localizer_data/val',\n",
    "    albu_transforms = [A.Normalize(p=1.0)],\n",
    "    end_transforms = [DownSample(down_ratio=down_ratio, anno_type='bbox')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.anno_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../wildlife_localizer_data/val/gt.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(labels['labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = DataLoader(dataset = val_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.transpose(images.numpy(),(1,2,0))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating YOLO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images dimensions\n",
    "height,width = 640, 640\n",
    "\n",
    "# Create label directory\n",
    "for directory in Path(\"../wildlife_localizer_data/\").iterdir():\n",
    "    if not directory.is_dir():\n",
    "        continue \n",
    "    labels_dir = Path(os.path.join(directory,'labels'))\n",
    "    labels_dir.mkdir(exist_ok=True,parents=False) # create directory if it does not exist\n",
    "    labels = pd.read_csv(os.path.join(directory,'gt.csv'))\n",
    "    #-- Saving labels in YOLO format\n",
    "    for img_filename,df_group in tqdm(labels.groupby(by='images'),desc=directory.name):\n",
    "        df_group['width'] = (df_group['x_max'] - df_group['x_min'])/width \n",
    "        df_group['height'] = (df_group['y_max'] - df_group['y_min'])/height\n",
    "        df_group['x'] = (0.5*(df_group['x_min'] + df_group['x_max']))/width # x center\n",
    "        df_group['y'] = (0.5*(df_group['y_min'] + df_group['y_max']))/height # y center\n",
    "        df_group['labels'] = 0 \n",
    "\n",
    "        # print('\\n\\n',directory.name,'\\n',df_group[['labels','x','y','width','height']])\n",
    "        # break\n",
    "\n",
    "        # uncomment to save labels files\n",
    "        labels_filename     = img_filename.split('.')[0] + '.txt'\n",
    "        if len(df_group)>0:\n",
    "            cols = ['labels','x','y','width','height']\n",
    "            df_group[cols].to_csv(os.path.join(labels_dir,labels_filename),\n",
    "                                    sep=\" \",\n",
    "                                    header=False,\n",
    "                                    index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2750/2750 [00:09<00:00, 303.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# for savmap data\n",
    "directory = Path(\"../savmap_dataset_v2/train/\")\n",
    "labels_dir = Path(os.path.join(directory,'labels'))\n",
    "labels_dir.mkdir(exist_ok=True,parents=False) # create directory if it does not exist\n",
    "labels = pd.read_csv(os.path.join(directory,'gt.csv'))\n",
    "#-- Saving labels in YOLO format\n",
    "for img_filename,df_group in tqdm(labels.groupby(by='images'),desc=directory.name):\n",
    "    df_group['width'] = (df_group['x_max'] - df_group['x_min'])/width \n",
    "    df_group['height'] = (df_group['y_max'] - df_group['y_min'])/height\n",
    "    df_group['x'] = (0.5*(df_group['x_min'] + df_group['x_max']))/width # x center\n",
    "    df_group['y'] = (0.5*(df_group['y_min'] + df_group['y_max']))/height # y center\n",
    "    df_group['labels'] = 0 \n",
    "\n",
    "    # print('\\n\\n',directory.name,'\\n',df_group[['labels','x','y','width','height']])\n",
    "    # break\n",
    "\n",
    "    # uncomment to save labels files\n",
    "    labels_filename = img_filename.split('.')[0] + '.txt'\n",
    "    if len(df_group)>0:\n",
    "        cols = ['labels','x','y','width','height']\n",
    "        df_group[cols].to_csv(os.path.join(labels_dir,labels_filename),\n",
    "                                    sep=\" \",\n",
    "                                    header=False,\n",
    "                                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30607, 2750, 33357)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control splitting\n",
    "num_missing = 0\n",
    "num_found = 0\n",
    "num_total = 0\n",
    "for path in Path(\"../savmap_dataset_v2/train/images\").iterdir():\n",
    "    filename = path.name.split('.')[0]\n",
    "    labelpath = Path(\"../savmap_dataset_v2/train/labels\")/(filename + '.txt')\n",
    "    num_total += 1\n",
    "    if not labelpath.exists():\n",
    "        num_missing += 1\n",
    "    else:\n",
    "        num_found += 1\n",
    "\n",
    "num_missing,num_found,num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(os.path.join(directory,'gt.csv'))\n",
    "labels['labels'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Savmap data\n",
    "Saving bounding boxes in VOC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import torch \n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.ops import nms\n",
    "from torchvision.transforms import PILToTensor\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = Path(\"../savmap_dataset/savmap_annotations_2014.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMAGEUUID</th>\n",
       "      <th>TAGUUID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f77f4af5a1344b9086b307d2b4ba61ff</td>\n",
       "      <td>a9b3a2325dbe4a208bc3ae37eeb8e1e1</td>\n",
       "      <td>POLYGON ((1197.000 568.000, 1186.000 568.000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33c79ba79aca4b06ae30a109e5cd868f</td>\n",
       "      <td>4999d35b3b8b407f8cbf48d95e689899</td>\n",
       "      <td>POLYGON ((2689.000 778.000, 2674.000 747.000, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12fe8b054f634ed0a0ffc5d7ed614b66</td>\n",
       "      <td>8d61ca1969b149cbaed4a9bd112c771f</td>\n",
       "      <td>POLYGON ((3157.000 2721.000, 3224.000 2725.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18c3f7ef05c74a849d2262786d71819e</td>\n",
       "      <td>5be6cc29725140b58e8d5fe5eba9b379</td>\n",
       "      <td>POLYGON ((3559.000 2707.000, 3571.000 2708.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18c3f7ef05c74a849d2262786d71819e</td>\n",
       "      <td>0093c3c4285a4eeaba82f29fb86b3c8a</td>\n",
       "      <td>POLYGON ((437.000 606.000, 420.000 621.000, 42...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          IMAGEUUID                           TAGUUID  \\\n",
       "0  f77f4af5a1344b9086b307d2b4ba61ff  a9b3a2325dbe4a208bc3ae37eeb8e1e1   \n",
       "1  33c79ba79aca4b06ae30a109e5cd868f  4999d35b3b8b407f8cbf48d95e689899   \n",
       "2  12fe8b054f634ed0a0ffc5d7ed614b66  8d61ca1969b149cbaed4a9bd112c771f   \n",
       "3  18c3f7ef05c74a849d2262786d71819e  5be6cc29725140b58e8d5fe5eba9b379   \n",
       "4  18c3f7ef05c74a849d2262786d71819e  0093c3c4285a4eeaba82f29fb86b3c8a   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((1197.000 568.000, 1186.000 568.000, ...  \n",
       "1  POLYGON ((2689.000 778.000, 2674.000 747.000, ...  \n",
       "2  POLYGON ((3157.000 2721.000, 3224.000 2725.000...  \n",
       "3  POLYGON ((3559.000 2707.000, 3571.000 2708.000...  \n",
       "4  POLYGON ((437.000 606.000, 420.000 621.000, 42...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gpd.read_file(annotations_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[data['IMAGEUUID']=='0a3ed15cfab4453795564140e8fde8ba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uuid = '0a3ed15cfab4453795564140e8fde8ba'\n",
    "# polygons = data.loc[data['IMAGEUUID']==uuid,'geometry']\n",
    "# polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting bbox:   0%|          | 0/654 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting bbox: 100%|██████████| 654/654 [02:37<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "bboxes = dict()\n",
    "count = 0\n",
    "pil_to_tensor = PILToTensor()\n",
    "for uuid in tqdm(np.unique(data.IMAGEUUID),desc='Getting bbox'):\n",
    "\n",
    "    # identifier, filenmae w/o suffix\n",
    "    uuid = str(uuid)\n",
    "\n",
    "    # load img as tensor\n",
    "    path_to_img = f\"../savmap_dataset/{uuid}.JPG\"\n",
    "    img_pil = Image.open(path_to_img)\n",
    "    img_tensor = pil_to_tensor(img_pil)\n",
    "\n",
    "    # get boxes\n",
    "    polygons = data.loc[data['IMAGEUUID']==uuid,'geometry']\n",
    "    boxes = np.array([list(polygon.bounds) for polygon in polygons])\n",
    "    boxes = torch.from_numpy(boxes).float()\n",
    "\n",
    "    # apply non max suppression o discard overlaping polygons\n",
    "    areas = abs((boxes[:,2] - boxes[:,0])*(boxes[:,3] - boxes[:,1]))\n",
    "    indices = nms(boxes=boxes,\n",
    "                  scores= 1/areas, # discarding larger bbox when they overlap\n",
    "                  iou_threshold=0.1)\n",
    "    bbox = boxes[indices].numpy()\n",
    "\n",
    "    # save bbox\n",
    "    for idx,i in enumerate(range(count,count+bbox.shape[0])):\n",
    "        bboxes[i] = [uuid,] + bbox[idx].tolist()\n",
    "    count = count+bbox.shape[0]\n",
    "# print('retained bbox indes:',indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003a34ee6b7841e6851b8fe511ebe102.JPG</td>\n",
       "      <td>1679</td>\n",
       "      <td>858</td>\n",
       "      <td>1695</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003a34ee6b7841e6851b8fe511ebe102.JPG</td>\n",
       "      <td>1503</td>\n",
       "      <td>962</td>\n",
       "      <td>1537</td>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0078d29a8d0b489caa3425969c7477ac.JPG</td>\n",
       "      <td>2781</td>\n",
       "      <td>541</td>\n",
       "      <td>2822</td>\n",
       "      <td>577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0078d29a8d0b489caa3425969c7477ac.JPG</td>\n",
       "      <td>543</td>\n",
       "      <td>1725</td>\n",
       "      <td>603</td>\n",
       "      <td>1754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0078d29a8d0b489caa3425969c7477ac.JPG</td>\n",
       "      <td>620</td>\n",
       "      <td>1653</td>\n",
       "      <td>677</td>\n",
       "      <td>1689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 images  x_min  y_min  x_max  y_max  labels\n",
       "0  003a34ee6b7841e6851b8fe511ebe102.JPG   1679    858   1695    875       0\n",
       "1  003a34ee6b7841e6851b8fe511ebe102.JPG   1503    962   1537    996       0\n",
       "2  0078d29a8d0b489caa3425969c7477ac.JPG   2781    541   2822    577       0\n",
       "3  0078d29a8d0b489caa3425969c7477ac.JPG    543   1725    603   1754       0\n",
       "4  0078d29a8d0b489caa3425969c7477ac.JPG    620   1653    677   1689       0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['images','x_min','y_min','x_max','y_max']\n",
    "gt_bboxes = pd.DataFrame.from_dict(data=bboxes,\n",
    "                       orient='index',\n",
    "                       columns=columns)\n",
    "\n",
    "for col in columns:\n",
    "    if col != 'images':\n",
    "        gt_bboxes[col] = gt_bboxes[col].apply(int)\n",
    "    else:\n",
    "        gt_bboxes[col] = gt_bboxes[col].apply(lambda x: f\"{x}.JPG\")\n",
    "\n",
    "gt_bboxes['labels'] = 0 # class\n",
    "gt_bboxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discarding invalid coordinates\n",
    "# gt_bboxes.loc[gt_bboxes.min(axis=1,numeric_only=True)>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save valid bounding boxes\n",
    "# mask = gt_bboxes.min(axis=1,numeric_only=True)>=0\n",
    "# gt_bboxes.loc[mask].to_csv(\"../savmap_dataset_v2/gt.csv\",sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: drawing bounding boxes\n",
    "\n",
    "# load img as tensor\n",
    "filename = gt_bboxes['filename'].sample(1).iloc[0]\n",
    "path_to_img = f\"../savmap_dataset/{filename}\"\n",
    "img_pil = Image.open(path_to_img)\n",
    "img_tensor = PILToTensor()(img_pil)\n",
    "\n",
    "boxes = gt_bboxes.loc[gt_bboxes['filename'] == filename, ['xmin','ymin','xmax','ymax']].to_numpy()\n",
    "boxes = torch.from_numpy(boxes)\n",
    "\n",
    "img_with_box = draw_bounding_boxes(img_tensor,\n",
    "                                   boxes=boxes,\n",
    "                                   colors=\"red\",\n",
    "                                   width=5).numpy().transpose((1,2,0))\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.imshow(img_with_box)\n",
    "plt.title(filename)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "herdnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
