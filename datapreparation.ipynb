{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import PIL\n",
    "import torchvision\n",
    "import numpy\n",
    "import cv2\n",
    "import skimage\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from albumentations import PadIfNeeded\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from animaloc.data import ImageToPatches, PatchesBuffer, save_batch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data for annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For GeoTiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patches(img_path:Path,dest_dir:Path,tilesize=512):\n",
    "\n",
    "    # create directory\n",
    "    if os.path.exists(dest_dir):\n",
    "        shutil.rmtree(dest_dir)\n",
    "        os.mkdir(dest_dir)\n",
    "        print(\"emptying directory:\", dest_dir)\n",
    "    else:\n",
    "        os.mkdir(dest_dir)\n",
    "        print(\"creating directory:\", dest_dir)\n",
    "    \n",
    "    # window reading with rasterio\n",
    "    handler = rasterio.open(img_path)\n",
    "    height, width = handler.meta['height'], handler.meta['width']\n",
    "    coordinates = dict()\n",
    "    count = 0\n",
    "    for i,j in tqdm(product(list(range(0,height,tilesize)),list(range(0,width,tilesize)))):\n",
    "        window = Window(j, i, tilesize, tilesize)\n",
    "        \n",
    "        try:\n",
    "            chunk = handler.read(window=window)\n",
    "            c,h,w = chunk.shape\n",
    "            xmin, xmax = j, j+w\n",
    "            ymin, ymax = i, i+h\n",
    "            x_center = 0.5*(xmin+xmax)\n",
    "            y_center = 0.5*(ymin+ymax)\n",
    "            n_unique = np.unique(chunk).size\n",
    "            if n_unique == 1:\n",
    "                continue\n",
    "            count += 1\n",
    "            filename = img_path.name.split('.')[0] + f\"-{j}-{i}.png\"\n",
    "            coordinates[count] = [xmin,xmax,ymin,ymax,x_center,y_center,filename]\n",
    "\n",
    "            # save to disk\n",
    "            chunk = np.transpose(chunk,(1,2,0))\n",
    "            skimage.io.imsave(dest_dir/filename,chunk)          \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Failed for\",(i,j),e)\n",
    "            pass\n",
    "\n",
    "    cols = ['xmin','xmax','ymin','ymax','x_center','y_center','filename']\n",
    "    coordinates = pd.DataFrame.from_dict(coordinates,\n",
    "                                        orient='index',\n",
    "                                        columns=cols)\n",
    "    coordinates.to_csv(dest_dir/f\"coordinates{img_path.name.split('.')[0]}.csv\",index=False)\n",
    "    handler.close()\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datapath in Path(\"../annotation_data/camp6/\").iterdir():\n",
    "datapath = Path(\"../annotation_data/camp6/150m_RGB.tif\")\n",
    "dest_dir = datapath.parent/(datapath.name.split('.')[0])\n",
    "# coordinates =  save_patches(datapath,dest_dir,tilesize=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Images (jpg, rgb etc.)\n",
    "Using Herdnet code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd # current working dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting validation data\n",
    "Path(\"../general_dataset/val_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../general_dataset/val 640 640 100 \\\n",
    "    ../general_dataset/val_splits \\\n",
    "    -csv ../general_dataset/groundtruth/csv/val_big_size_A_B_E_K_WH_WB.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training data\n",
    "Path(\"../general_dataset/train_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../general_dataset/train 640 640 100 \\\n",
    "    ../general_dataset/train_splits \\\n",
    "    -csv ../general_dataset/groundtruth/csv/train_big_size_A_B_E_K_WH_WB.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting test data\n",
    "Path(\"../general_dataset/test_splits\").mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "!python ./tools/patcher.py ../general_dataset/test 640 640 100 \\\n",
    "    ../general_dataset/test_splits \\\n",
    "    -csv ../general_dataset/groundtruth/csv/test_big_size_A_B_E_K_WH_WB.csv \\\n",
    "    -min 0.0 -all False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling emtpy and non empty images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample training data\n",
    "\n",
    "directory = Path(r\"../wildlife_localizer_data/train\")\n",
    "labels = directory/'labels'\n",
    "dest_images = directory/'images_nonempty'\n",
    "source_images = directory/'images'\n",
    "\n",
    "# create destination images\n",
    "dest_images.mkdir(exist_ok=True)\n",
    "\n",
    "# move non empty images\n",
    "# -- Uncomment to run > Be careful\n",
    "# for file in labels.iterdir():\n",
    "#     img_name = file.name.split('.')[0]+'.JPG'\n",
    "#     if (source_images/img_name).exists():\n",
    "#         os.rename(src=source_images/img_name,\n",
    "#                 dst=dest_images/img_name)\n",
    "\n",
    "# and empty \n",
    "# num_non_empty = len(list(labels.iterdir()))\n",
    "# num_empty_target = num_non_empty\n",
    "# empty_images = list(source_images.iterdir())\n",
    "# random.seed(41) # seeding for reproducibility\n",
    "# random.shuffle(empty_images) # shuffle\n",
    "# for file in empty_images[:num_empty_target]:\n",
    "#     img_name = file.name\n",
    "#     os.rename(src=file,\n",
    "#                 dst=dest_images/img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(Path(\"../wildlife_localizer_data/train/images_nonempty\").iterdir())),\\\n",
    "    len(list(Path(\"../wildlife_localizer_data/train/images\").iterdir())),\\\n",
    "        len(list(Path(\"../wildlife_localizer_data/train/labels\").iterdir()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from animaloc.datasets import CSVDataset\n",
    "from animaloc.data.transforms import MultiTransformsWrapper, DownSample, PointsToMask, FIDT\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_size = 640\n",
    "# num_classes = 7\n",
    "down_ratio = 1\n",
    "\n",
    "val_dataset = CSVDataset(\n",
    "    csv_file = '../wildlife_localizer_data/val/gt.csv',\n",
    "    root_dir = '../wildlife_localizer_data/val',\n",
    "    albu_transforms = [A.Normalize(p=1.0)],\n",
    "    end_transforms = [DownSample(down_ratio=down_ratio, anno_type='bbox')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.anno_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../wildlife_localizer_data/val/gt.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(labels['labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = DataLoader(dataset = val_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.transpose(images.numpy(),(1,2,0))\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating YOLO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images dimensions\n",
    "height,width = 640, 640\n",
    "\n",
    "# Create label directory\n",
    "for directory in Path(\"../wildlife_localizer_data/\").iterdir():\n",
    "    if not directory.is_dir():\n",
    "        continue \n",
    "    labels_dir = Path(os.path.join(directory,'labels'))\n",
    "    labels_dir.mkdir(exist_ok=True,parents=False) # create directory if it does not exist\n",
    "    labels = pd.read_csv(os.path.join(directory,'gt.csv'))\n",
    "    #-- Saving labels in YOLO format\n",
    "    for img_filename,df_group in tqdm(labels.groupby(by='images'),desc=directory.name):\n",
    "        df_group['width'] = (df_group['x_max'] - df_group['x_min'])/width \n",
    "        df_group['height'] = (df_group['y_max'] - df_group['y_min'])/height\n",
    "        df_group['x'] = (0.5*(df_group['x_min'] + df_group['x_max']))/width # x center\n",
    "        df_group['y'] = (0.5*(df_group['y_min'] + df_group['y_max']))/height # y center\n",
    "        df_group['labels'] = 0 \n",
    "\n",
    "        # print('\\n\\n',directory.name,'\\n',df_group[['labels','x','y','width','height']])\n",
    "        # break\n",
    "\n",
    "        # uncomment to save labels files\n",
    "        labels_filename     = img_filename.split('.')[0] + '.txt'\n",
    "        if len(df_group)>0:\n",
    "            cols = ['labels','x','y','width','height']\n",
    "            df_group[cols].to_csv(os.path.join(labels_dir,labels_filename),\n",
    "                                    sep=\" \",\n",
    "                                    header=False,\n",
    "                                    index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control splitting\n",
    "num_missing = 0\n",
    "num_found = 0\n",
    "num_total = 0\n",
    "for path in Path(\"../wildlife_localizer_data/train/images\").iterdir():\n",
    "    filename = path.name.split('.')[0]\n",
    "    labelpath = Path(\"../wildlife_localizer_data/train/labels\")/(filename + '.txt')\n",
    "    num_total += 1\n",
    "    if not labelpath.exists():\n",
    "        num_missing += 1\n",
    "    else:\n",
    "        num_found += 1\n",
    "\n",
    "num_missing,num_found,num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(os.path.join(directory,'gt.csv'))\n",
    "labels['labels'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Savmap data\n",
    "Saving bounding boxes in VOC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import torch \n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.ops import nms\n",
    "from torchvision.transforms import PILToTensor\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = Path(\"../savmap_dataset/savmap_annotations_2014.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpd.read_file(annotations_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['IMAGEUUID']=='0a3ed15cfab4453795564140e8fde8ba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid = '0a3ed15cfab4453795564140e8fde8ba'\n",
    "polygons = data.loc[data['IMAGEUUID']==uuid,'geometry']\n",
    "polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = dict()\n",
    "count = 0\n",
    "pil_to_tensor = PILToTensor()\n",
    "for uuid in tqdm(np.unique(data.IMAGEUUID),desc='Getting bbox'):\n",
    "\n",
    "    # identifier, filenmae w/o suffix\n",
    "    uuid = str(uuid)\n",
    "\n",
    "    # load img as tensor\n",
    "    path_to_img = f\"../savmap_dataset/{uuid}.JPG\"\n",
    "    img_pil = Image.open(path_to_img)\n",
    "    img_tensor = pil_to_tensor(img_pil)\n",
    "\n",
    "    # get boxes\n",
    "    polygons = data.loc[data['IMAGEUUID']==uuid,'geometry']\n",
    "    boxes = np.array([list(polygon.bounds) for polygon in polygons])\n",
    "    boxes = torch.from_numpy(boxes).float()\n",
    "\n",
    "    # apply non max suppression o discard overlaping polygons\n",
    "    areas = (boxes[:,2] - boxes[:,0])*(boxes[:,3] - boxes[:,1])\n",
    "    indices = nms(boxes=boxes,\n",
    "                  scores= 1/areas, # discarding larger bbox when they overlap\n",
    "                  iou_threshold=0.1)\n",
    "    bbox = boxes[indices].numpy()\n",
    "\n",
    "    # save bbox\n",
    "    for i in range(count,count+bbox.shape[0]):\n",
    "        bboxes[i] = [uuid,] + bbox[i-count].tolist()\n",
    "    count = count+bbox.shape[0]\n",
    "# print('retained bbox indes:',indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['filename','xmin','ymin','xmax','ymax']\n",
    "gt_bboxes = pd.DataFrame.from_dict(data=bboxes,\n",
    "                       orient='index',\n",
    "                       columns=columns)\n",
    "\n",
    "for col in columns:\n",
    "    if col != 'filename':\n",
    "        gt_bboxes[col] = gt_bboxes[col].apply(int)\n",
    "    else:\n",
    "        gt_bboxes[col] = gt_bboxes[col].apply(lambda x: f\"{x}.JPG\")\n",
    "\n",
    "gt_bboxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bounding boxes\n",
    "# gt_bboxes.to_csv(\"../savmap_dataset/gt.csv\",sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: drawing bounding boxes\n",
    "\n",
    "# load img as tensor\n",
    "filename = gt_bboxes['filename'].sample(1).iloc[0]\n",
    "path_to_img = f\"../savmap_dataset/{filename}\"\n",
    "img_pil = Image.open(path_to_img)\n",
    "img_tensor = PILToTensor()(img_pil)\n",
    "\n",
    "boxes = gt_bboxes.loc[gt_bboxes['filename'] == filename, ['xmin','ymin','xmax','ymax']].to_numpy()\n",
    "boxes = torch.from_numpy(boxes)\n",
    "\n",
    "img_with_box = draw_bounding_boxes(img_tensor,\n",
    "                                   boxes=boxes,\n",
    "                                   colors=\"red\",\n",
    "                                   width=5).numpy().transpose((1,2,0))\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.imshow(img_with_box)\n",
    "plt.title(filename)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "herdnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
